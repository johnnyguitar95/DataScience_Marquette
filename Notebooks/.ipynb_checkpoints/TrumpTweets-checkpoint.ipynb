{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#all imports, library setups here\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import nltk\n",
    "#nltk.download()\n",
    "#from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "import operator\n",
    "from collections import Counter\n",
    "\n",
    "from scipy import stats, integrate\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import cufflinks as cf\n",
    "\n",
    "import plotly\n",
    "plotly.offline.init_notebook_mode()\n",
    "import plotly.offline as py\n",
    "import plotly.graph_objs as go\n",
    "from plotly.graph_objs import *\n",
    "print(pd.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "donald_tweets = pd.read_csv('Donald_Trump_Tweets.csv', sep=\",\", header='infer', encoding = 'latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Tweet_Text</th>\n",
       "      <th>Type</th>\n",
       "      <th>Media_Type</th>\n",
       "      <th>Hashtags</th>\n",
       "      <th>Tweet_Id</th>\n",
       "      <th>Tweet_Url</th>\n",
       "      <th>twt_favourites</th>\n",
       "      <th>Retweets</th>\n",
       "      <th>Unnamed: 10</th>\n",
       "      <th>Unnamed: 11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16-11-11</td>\n",
       "      <td>15:26:37</td>\n",
       "      <td>Today we express our deepest gratitude to all ...</td>\n",
       "      <td>text</td>\n",
       "      <td>photo</td>\n",
       "      <td>ThankAVet</td>\n",
       "      <td>7.970000e+17</td>\n",
       "      <td>https://twitter.com/realDonaldTrump/status/797...</td>\n",
       "      <td>127213</td>\n",
       "      <td>41112</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16-11-11</td>\n",
       "      <td>13:33:35</td>\n",
       "      <td>Busy day planned in New York. Will soon be mak...</td>\n",
       "      <td>text</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.970000e+17</td>\n",
       "      <td>https://twitter.com/realDonaldTrump/status/797...</td>\n",
       "      <td>141527</td>\n",
       "      <td>28654</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16-11-11</td>\n",
       "      <td>11:14:20</td>\n",
       "      <td>Love the fact that the small groups of protest...</td>\n",
       "      <td>text</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.970000e+17</td>\n",
       "      <td>https://twitter.com/realDonaldTrump/status/797...</td>\n",
       "      <td>183729</td>\n",
       "      <td>50039</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16-11-11</td>\n",
       "      <td>2:19:44</td>\n",
       "      <td>Just had a very open and successful presidenti...</td>\n",
       "      <td>text</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.970000e+17</td>\n",
       "      <td>https://twitter.com/realDonaldTrump/status/796...</td>\n",
       "      <td>214001</td>\n",
       "      <td>67010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16-11-11</td>\n",
       "      <td>2:10:46</td>\n",
       "      <td>A fantastic day in D.C. Met with President Oba...</td>\n",
       "      <td>text</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.970000e+17</td>\n",
       "      <td>https://twitter.com/realDonaldTrump/status/796...</td>\n",
       "      <td>178499</td>\n",
       "      <td>36688</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Date      Time                                         Tweet_Text  \\\n",
       "0  16-11-11  15:26:37  Today we express our deepest gratitude to all ...   \n",
       "1  16-11-11  13:33:35  Busy day planned in New York. Will soon be mak...   \n",
       "2  16-11-11  11:14:20  Love the fact that the small groups of protest...   \n",
       "3  16-11-11   2:19:44  Just had a very open and successful presidenti...   \n",
       "4  16-11-11   2:10:46  A fantastic day in D.C. Met with President Oba...   \n",
       "\n",
       "   Type Media_Type   Hashtags      Tweet_Id  \\\n",
       "0  text      photo  ThankAVet  7.970000e+17   \n",
       "1  text        NaN        NaN  7.970000e+17   \n",
       "2  text        NaN        NaN  7.970000e+17   \n",
       "3  text        NaN        NaN  7.970000e+17   \n",
       "4  text        NaN        NaN  7.970000e+17   \n",
       "\n",
       "                                           Tweet_Url  twt_favourites  \\\n",
       "0  https://twitter.com/realDonaldTrump/status/797...          127213   \n",
       "1  https://twitter.com/realDonaldTrump/status/797...          141527   \n",
       "2  https://twitter.com/realDonaldTrump/status/797...          183729   \n",
       "3  https://twitter.com/realDonaldTrump/status/796...          214001   \n",
       "4  https://twitter.com/realDonaldTrump/status/796...          178499   \n",
       "\n",
       "   Retweets  Unnamed: 10  Unnamed: 11  \n",
       "0     41112          NaN          NaN  \n",
       "1     28654          NaN          NaN  \n",
       "2     50039          NaN          NaN  \n",
       "3     67010          NaN          NaN  \n",
       "4     36688          NaN          NaN  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "donald_tweets.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Tweet_Text</th>\n",
       "      <th>Type</th>\n",
       "      <th>Media_Type</th>\n",
       "      <th>Hashtags</th>\n",
       "      <th>Tweet_Id</th>\n",
       "      <th>Tweet_Url</th>\n",
       "      <th>twt_favourites</th>\n",
       "      <th>Retweets</th>\n",
       "      <th>Unnamed: 10</th>\n",
       "      <th>Unnamed: 11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11/11/2016</td>\n",
       "      <td>15:26:37</td>\n",
       "      <td>Today we express our deepest gratitude to all ...</td>\n",
       "      <td>text</td>\n",
       "      <td>photo</td>\n",
       "      <td>ThankAVet</td>\n",
       "      <td>7.970000e+17</td>\n",
       "      <td>https://twitter.com/realDonaldTrump/status/797...</td>\n",
       "      <td>127213</td>\n",
       "      <td>41112</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11/11/2016</td>\n",
       "      <td>13:33:35</td>\n",
       "      <td>Busy day planned in New York. Will soon be mak...</td>\n",
       "      <td>text</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.970000e+17</td>\n",
       "      <td>https://twitter.com/realDonaldTrump/status/797...</td>\n",
       "      <td>141527</td>\n",
       "      <td>28654</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11/11/2016</td>\n",
       "      <td>11:14:20</td>\n",
       "      <td>Love the fact that the small groups of protest...</td>\n",
       "      <td>text</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.970000e+17</td>\n",
       "      <td>https://twitter.com/realDonaldTrump/status/797...</td>\n",
       "      <td>183729</td>\n",
       "      <td>50039</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11/11/2016</td>\n",
       "      <td>2:19:44</td>\n",
       "      <td>Just had a very open and successful presidenti...</td>\n",
       "      <td>text</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.970000e+17</td>\n",
       "      <td>https://twitter.com/realDonaldTrump/status/796...</td>\n",
       "      <td>214001</td>\n",
       "      <td>67010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11/11/2016</td>\n",
       "      <td>2:10:46</td>\n",
       "      <td>A fantastic day in D.C. Met with President Oba...</td>\n",
       "      <td>text</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.970000e+17</td>\n",
       "      <td>https://twitter.com/realDonaldTrump/status/796...</td>\n",
       "      <td>178499</td>\n",
       "      <td>36688</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date      Time                                         Tweet_Text  \\\n",
       "0  11/11/2016  15:26:37  Today we express our deepest gratitude to all ...   \n",
       "1  11/11/2016  13:33:35  Busy day planned in New York. Will soon be mak...   \n",
       "2  11/11/2016  11:14:20  Love the fact that the small groups of protest...   \n",
       "3  11/11/2016   2:19:44  Just had a very open and successful presidenti...   \n",
       "4  11/11/2016   2:10:46  A fantastic day in D.C. Met with President Oba...   \n",
       "\n",
       "   Type Media_Type   Hashtags      Tweet_Id  \\\n",
       "0  text      photo  ThankAVet  7.970000e+17   \n",
       "1  text        NaN        NaN  7.970000e+17   \n",
       "2  text        NaN        NaN  7.970000e+17   \n",
       "3  text        NaN        NaN  7.970000e+17   \n",
       "4  text        NaN        NaN  7.970000e+17   \n",
       "\n",
       "                                           Tweet_Url  twt_favourites  \\\n",
       "0  https://twitter.com/realDonaldTrump/status/797...          127213   \n",
       "1  https://twitter.com/realDonaldTrump/status/797...          141527   \n",
       "2  https://twitter.com/realDonaldTrump/status/797...          183729   \n",
       "3  https://twitter.com/realDonaldTrump/status/796...          214001   \n",
       "4  https://twitter.com/realDonaldTrump/status/796...          178499   \n",
       "\n",
       "   Retweets  Unnamed: 10  Unnamed: 11  \n",
       "0     41112          NaN          NaN  \n",
       "1     28654          NaN          NaN  \n",
       "2     50039          NaN          NaN  \n",
       "3     67010          NaN          NaN  \n",
       "4     36688          NaN          NaN  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Cleaning date data - want to convert from YY-MM-DD to MM/DD/YYYY\n",
    "numRows = len(donald_tweets['Date'])\n",
    "count = 0\n",
    "while (count < numRows):\n",
    "    tmp = donald_tweets['Date'][count]\n",
    "    tmp = tmp[3:5] + \"/\" + tmp[6:] + \"/20\" + tmp[0:2]\n",
    "    #print(tmp)\n",
    "    #print(donald_tweets['Date'][count])\n",
    "    donald_tweets.set_value(count, 'Date', tmp)\n",
    "    count = count + 1\n",
    "donald_tweets.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource 'tokenizers/punkt/english.pickle' not found.  Please\n  use the NLTK Downloader to obtain the resource:  >>>\n  nltk.download()\n  Searched in:\n    - 'C:\\\\Users\\\\Owner/nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n    - 'C:\\\\Users\\\\Owner\\\\Anaconda3\\\\nltk_data'\n    - 'C:\\\\Users\\\\Owner\\\\Anaconda3\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\Owner\\\\AppData\\\\Roaming\\\\nltk_data'\n    - ''\n**********************************************************************",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-66-fd0874b9971e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[1;31m#Preprocess\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtweet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdonald_tweets\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Tweet_Text'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtweet\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mC:\\Users\\Owner\\Anaconda3\\lib\\site-packages\\nltk\\tokenize\\__init__.py\u001b[0m in \u001b[0;36mword_tokenize\u001b[0;34m(text, language)\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[1;33m:\u001b[0m\u001b[0mparam\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mPunkt\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \"\"\"\n\u001b[0;32m--> 106\u001b[0;31m     return [token for sent in sent_tokenize(text, language)\n\u001b[0m\u001b[1;32m    107\u001b[0m             for token in _treebank_word_tokenize(sent)]\n\u001b[1;32m    108\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Owner\\Anaconda3\\lib\\site-packages\\nltk\\tokenize\\__init__.py\u001b[0m in \u001b[0;36msent_tokenize\u001b[0;34m(text, language)\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[1;33m:\u001b[0m\u001b[0mparam\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mPunkt\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \"\"\"\n\u001b[0;32m---> 90\u001b[0;31m     \u001b[0mtokenizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'tokenizers/punkt/{0}.pickle'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Owner\\Anaconda3\\lib\\site-packages\\nltk\\data.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(resource_url, format, cache, verbose, logic_parser, fstruct_reader, encoding)\u001b[0m\n\u001b[1;32m    799\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    800\u001b[0m     \u001b[1;31m# Load the resource.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 801\u001b[0;31m     \u001b[0mopened_resource\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresource_url\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    802\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    803\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mformat\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'raw'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Owner\\Anaconda3\\lib\\site-packages\\nltk\\data.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(resource_url)\u001b[0m\n\u001b[1;32m    917\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    918\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mprotocol\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'nltk'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 919\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    920\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'file'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    921\u001b[0m         \u001b[1;31m# urllib might not use mode='rb', so handle this one ourselves:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Owner\\Anaconda3\\lib\\site-packages\\nltk\\data.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    639\u001b[0m     \u001b[0msep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'*'\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m70\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'\\n%s\\n%s\\n%s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 641\u001b[0;31m     \u001b[1;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    642\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource 'tokenizers/punkt/english.pickle' not found.  Please\n  use the NLTK Downloader to obtain the resource:  >>>\n  nltk.download()\n  Searched in:\n    - 'C:\\\\Users\\\\Owner/nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n    - 'C:\\\\Users\\\\Owner\\\\Anaconda3\\\\nltk_data'\n    - 'C:\\\\Users\\\\Owner\\\\Anaconda3\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\Owner\\\\AppData\\\\Roaming\\\\nltk_data'\n    - ''\n**********************************************************************"
     ]
    }
   ],
   "source": [
    "#Preprocess \n",
    "tweet = donald_tweets['Tweet_Text'][0]\n",
    "print(word_tokenize(tweet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numRows = len(donald_tweets['Tweet_Text'])\n",
    "count = 0\n",
    "count_all = Counter()\n",
    "while (count < numRows):\n",
    "    terms_all = [term for term in preprocess]\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
